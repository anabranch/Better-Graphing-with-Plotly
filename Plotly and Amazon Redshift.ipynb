{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will go over one of the easiest ways to graph data from your [Amazon Redshift data warehouse](http://aws.amazon.com/redshift/) using [Plotly's public platform](https://plot.ly/) for publishing beautiful, interactive graphs from Python to the web.\n",
    "\n",
    "[Plotly's Enterprise platform](https://plot.ly/product/enterprise/) allows for an easy way for your company to build and share graphs without the data leaving your servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function #python 3 support\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings() # this squashes insecure SSL warnings - DO NOT DO THIS ON PRODUCTION!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll me using [Amazon's Sample Data](http://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-create-sample-db.html) for this notebook. Although we won't be connecting through a JDBC/ODBC connection we'll be using the [fantastic psycopg2 package](http://initd.org/psycopg/docs/index.html) with the [SQLAlchemy](http://www.sqlalchemy.org/) package and pandas to make it simple to query and analyze our data.\n",
    "\n",
    "You'll need your [Redshift Endpoint URL](http://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-connect-to-cluster.html) in order to access your redshift instance. I've obscured mine below but yours will be in a format similar to `datawarehouse.some_chars_here.region_name.redshift.amazonaws.com` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then connecting is as easy as entering in the informaiton on your cluster properties, you'll need the username, password, port, hose and database name. As a friendly reminder, remember to keep login information out of version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redshift_endpoint = os.getenv(\"REDSHIFT_ENDPOINT\")\n",
    "redshift_user = os.getenv(\"REDSHIFT_USER\")\n",
    "redshift_pass = os.getenv(\"REDSHIFT_PASS\")\n",
    "port = 5439\n",
    "dbname = 'dev'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to connect to a Redshift database and I've included two below. We can use the SQLAlchemy package or we can use the raw psycopg2 package. Both will allow us to execute SQL queries and get results however the SQLAlchemy engine makes it easier to directly return our data as a dataframe using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine_string = \"postgresql+psycopg2://%s:%s@%s:%d/%s\" \\\n",
    "% (redshift_user, redshift_pass, redshift_endpoint, port, dbname)\n",
    "engine = create_engine(engine_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=redshift_endpoint, \n",
    "    user=redshift_user, \n",
    "    port=port, \n",
    "    password=redshift_pass, \n",
    "    dbname=dbname)\n",
    "cur = conn.cursor() # create a cursor for executing queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Loading in Data\n",
    "\n",
    "This next section goes over loading in the sample data from Amazon's sample database. If you're going to work with your own data you can easily skip this section.\n",
    "\n",
    "-----------------START DATA LOADING-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aws_key = os.getenv(\"AWS_ACCESS_KEY_ID\") # needed to access S3 Sample Data\n",
    "aws_secret = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "base_copy_string = \"\"\"copy %s from 's3://awssampledbuswest2/tickit/%s.txt' \n",
    "credentials 'aws_access_key_id=%s;aws_secret_access_key=%s' \n",
    "delimiter '%s';\"\"\" # the base COPY string that we'll be using\n",
    "\n",
    "#easily generate each table that we'll need to COPY data from\n",
    "tables = [\"users\", \"venue\", \"category\", \"date\", \"event\", \"listing\"]\n",
    "data_files = [\"allusers_pipe\", \"venue_pipe\", \"category_pipe\", \"date2008_pipe\", \"allevents_pipe\", \"listings_pipe\"]\n",
    "delimiters = [\"|\", \"|\", \"|\", \"|\", \"|\", \"|\", \"|\"]\n",
    "\n",
    "#the generated COPY statements we'll be using to load data;\n",
    "copy_statements = []\n",
    "for tab, f, delim in zip(tables, data_files, delimiters):\n",
    "    copy_statements.append(base_copy_string % (tab, f, aws_key, aws_secret, delim))\n",
    "\n",
    "# add in Sales data, delimited by '\\t'\n",
    "copy_statements.append(\"\"\"copy sales from 's3://awssampledbuswest2/tickit/sales_tab.txt' \n",
    "credentials 'aws_access_key_id=%s;aws_secret_access_key=%s' \n",
    "delimiter '\\t' timeformat 'MM/DD/YYYY HH:MI:SS';\"\"\" % (aws_key, aws_secret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Table Statements\n",
    "cur.execute(\"\"\"\n",
    "create table users(\n",
    "\tuserid integer not null distkey sortkey,\n",
    "\tusername char(8),\n",
    "\tfirstname varchar(30),\n",
    "\tlastname varchar(30),\n",
    "\tcity varchar(30),\n",
    "\tstate char(2),\n",
    "\temail varchar(100),\n",
    "\tphone char(14),\n",
    "\tlikesports boolean,\n",
    "\tliketheatre boolean,\n",
    "\tlikeconcerts boolean,\n",
    "\tlikejazz boolean,\n",
    "\tlikeclassical boolean,\n",
    "\tlikeopera boolean,\n",
    "\tlikerock boolean,\n",
    "\tlikevegas boolean,\n",
    "\tlikebroadway boolean,\n",
    "\tlikemusicals boolean);\n",
    "\n",
    "create table venue(\n",
    "\tvenueid smallint not null distkey sortkey,\n",
    "\tvenuename varchar(100),\n",
    "\tvenuecity varchar(30),\n",
    "\tvenuestate char(2),\n",
    "\tvenueseats integer);\n",
    "\n",
    "create table category(\n",
    "\tcatid smallint not null distkey sortkey,\n",
    "\tcatgroup varchar(10),\n",
    "\tcatname varchar(10),\n",
    "\tcatdesc varchar(50));\n",
    "\n",
    "create table date(\n",
    "\tdateid smallint not null distkey sortkey,\n",
    "\tcaldate date not null,\n",
    "\tday character(3) not null,\n",
    "\tweek smallint not null,\n",
    "\tmonth character(5) not null,\n",
    "\tqtr character(5) not null,\n",
    "\tyear smallint not null,\n",
    "\tholiday boolean default('N'));\n",
    "\n",
    "create table event(\n",
    "\teventid integer not null distkey,\n",
    "\tvenueid smallint not null,\n",
    "\tcatid smallint not null,\n",
    "\tdateid smallint not null sortkey,\n",
    "\teventname varchar(200),\n",
    "\tstarttime timestamp);\n",
    "\n",
    "create table listing(\n",
    "\tlistid integer not null distkey,\n",
    "\tsellerid integer not null,\n",
    "\teventid integer not null,\n",
    "\tdateid smallint not null  sortkey,\n",
    "\tnumtickets smallint not null,\n",
    "\tpriceperticket decimal(8,2),\n",
    "\ttotalprice decimal(8,2),\n",
    "\tlisttime timestamp);\n",
    "\n",
    "create table sales(\n",
    "\tsalesid integer not null,\n",
    "\tlistid integer not null distkey,\n",
    "\tsellerid integer not null,\n",
    "\tbuyerid integer not null,\n",
    "\teventid integer not null,\n",
    "\tdateid smallint not null sortkey,\n",
    "\tqtysold smallint not null,\n",
    "\tpricepaid decimal(8,2),\n",
    "\tcommission decimal(8,2),\n",
    "\tsaletime timestamp);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for copy_statement in copy_statements: # execute each COPY statement\n",
    "    cur.execute(copy_statement)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49990L,)\n",
      "(202L,)\n",
      "(11L,)\n",
      "(365L,)\n",
      "(8798L,)\n",
      "(192497L,)\n",
      "(172456L,)\n"
     ]
    }
   ],
   "source": [
    "for table in tables + [\"sales\"]:\n",
    "    cur.execute(\"select count(*) from %s;\" % (table,))    \n",
    "    print(cur.fetchone())\n",
    "conn.commit() # make sure data went through and commit our statements permanently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------END DATA LOADING-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished loading in our data, we can start running some queries to explore and present what our user's tastes and habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT sum(likesports::int) as sports, sum(liketheatre::int) as theatre,  \n",
    "sum(likeconcerts::int) as concerts, sum(likejazz::int) as jazz, \n",
    "sum(likeclassical::int) as classical, sum(likeopera::int) as opera,  \n",
    "sum(likerock::int) as rock, sum(likevegas::int) as vegas,  \n",
    "sum(likebroadway::int) as broadway, sum(likemusicals::int) as musical, \n",
    "state\n",
    "FROM users \n",
    "GROUP BY state;\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/140.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data([\n",
    "        Heatmap(\n",
    "            z = df.drop('state', axis=1).values,\n",
    "            x = df.drop('state', axis=1).columns,\n",
    "            y=df.state,\n",
    "            colorscale='Hot'\n",
    "        )\n",
    "    ])\n",
    "py.iplot(data, filename='redshift/state and music taste heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*the above graph is interactive, click and drag to zoom, double click to return to initial layout, shift click to pan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmaps are great because we can easily get a sense for activity. We can see that sports aren't popular amoung our users and taht certain states seem to have the greatest popularity across the board. \n",
    "\n",
    "Let's explore a bit further and see which group has the highest standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/182.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = Layout(title=\"Declared User Preference Box Plot\", \n",
    "                yaxis=YAxis())\n",
    "\n",
    "data = []\n",
    "for pref in df.drop('state', axis=1).columns:\n",
    "    data.append(Box(y=df[pref], name=pref))\n",
    "    \n",
    "py.iplot(\n",
    "    Figure(data=data, layout=layout)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*the above graph is interactive, click and drag to zoom, double click to return to initial layout, shift click to pan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've explored a little bit about the users, a logical next question is, do we list less sports events on our site? Or do we sell approximately the same amount of all event types and our users just seem to dislike sports events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT sum(event.catid) as category_sum, catname as category_name\n",
    "FROM event, category\n",
    "where event.catid = category.catid\n",
    "GROUP BY category.catname\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/183.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = Layout(title=\"Event Categories Sum\", yaxis=YAxis(title=\"Sum\"))\n",
    "data = [Bar(x=df.category_name, y=df.category_sum)]\n",
    "py.iplot(\n",
    "    Figure(data=data, layout=layout)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got to rush to management because we've got a significant discrepancy between the types of events that we are listing and our user's preferences! Let's dive a bit deeper into the events that we're listing and when we're listing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT sum(sales.qtysold) as quantity_sold, date.caldate  \n",
    "FROM sales, date\n",
    "WHERE sales.dateid = date.dateid \n",
    "GROUP BY date.caldate \n",
    "ORDER BY date.caldate asc;\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/184.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = Layout(title=\"Event Sales Per Day\", yaxis=YAxis(title=\"Sales Quantity\"))\n",
    "data = [Scatter(x=df.caldate, y=df.quantity_sold)]\n",
    "py.iplot(Figure(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT sum(sales.qtysold) as quantity_sold, date.caldate, category.catname as category_name  \n",
    "FROM sales, date, event, category\n",
    "WHERE sales.dateid = date.dateid \n",
    "AND sales.eventid = event.eventid\n",
    "AND event.catid = category.catid\n",
    "GROUP BY date.caldate, category_name\n",
    "ORDER BY date.caldate asc;\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bill_chambers/.virtualenvs/plotly-notebook/lib/python2.7/site-packages/plotly/tools.py:438: UserWarning:\n",
      "\n",
      "tools.get_subplots is depreciated. Please use tools.make_subplots instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/185.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for count, (name, g) in enumerate(df.groupby(\"category_name\")):\n",
    "    data.append(Scatter(\n",
    "            name=name,\n",
    "            x=g.caldate,\n",
    "            y=g.quantity_sold,\n",
    "            xaxis='x' + str(count + 1),\n",
    "            yaxis='y' + str(count + 1)\n",
    "        ))\n",
    "\n",
    "fig = tls.get_subplots(rows=2,columns=2)\n",
    "fig['layout'].update(title=\"Event Sales Per Day By Category\")\n",
    "fig['data'] += data\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~bill_chambers/186.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for name, g in df.groupby(\"category_name\"):\n",
    "    data.append(Scatter(\n",
    "            name=name,\n",
    "            x=g.caldate,\n",
    "            y=g.quantity_sold\n",
    "        ))\n",
    "\n",
    "fig = Figure()\n",
    "fig['layout'].update(title=\"Event Sales Per Day By Category\")\n",
    "fig['data'] += data\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
